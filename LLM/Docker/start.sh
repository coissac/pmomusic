#!/bin/bash
set -e

# Lancer Ollama en arriÃ¨re-plan
export OLLAMA_MODELS=/models
echo "ðŸ”¹ DÃ©marrage de Ollama..." 1>&2
ollama serve | sed 's/^/ ðŸ”¹[Ollama server] /'  &

sleep 10

echo "ðŸ”¹ Preaload Ollama models: "
ollama ls  | sed 's/^/ ðŸ”¹ /' 1>&2

# Attendre Ollama
sleep 5

# VÃ©rifier / prÃ©charger le modÃ¨le Nomic Embed Text
EMBED_MODEL="nomic-embed-text:latest"

echo "ðŸ”¹ VÃ©rification du modÃ¨le d'embedding: $EMBED_MODEL" 1>&2
if ! ollama list | grep -q "$EMBED_MODEL"; then
    echo " ðŸ”¹ ModÃ¨le $EMBED_MODEL non trouvÃ©, tÃ©lÃ©chargement..." 1>&2
    ollama pull "$EMBED_MODEL"
else
    echo " ðŸ”¹ ModÃ¨le $EMBED_MODEL dÃ©jÃ  prÃ©sent" 1>&2
fi

echo "ðŸ”¹ VÃ©rification du modÃ¨le LLM: $OLLAMA_MODEL" 1>&2
if ! ollama list | grep -q "$OLLAMA_MODEL"; then
    echo " ðŸ”¹ ModÃ¨le $OLLAMA_MODEL non trouvÃ©, tÃ©lÃ©chargement..." 1>&2
    ollama pull "$OLLAMA_MODEL"
else
    echo " ðŸ”¹ ModÃ¨le $OLLAMA_MODEL dÃ©jÃ  prÃ©sent" 1>&2
fi


# Lancer FastAPI
echo "ðŸ”¹ DÃ©marrage de FastAPI..." 1>&2
exec uvicorn app:app --host 0.0.0.0 --port 8000 --reload
